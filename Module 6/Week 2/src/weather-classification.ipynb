{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Classification using ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed = 59\n",
    "set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of dataset\n",
    "root_dir = '../data/weather-dataset/dataset'\n",
    "img_paths = []\n",
    "labels = []\n",
    "classes = {\n",
    "    label_idx: class_name for label_idx, class_name in enumerate(\n",
    "            sorted(os.listdir(root_dir))\n",
    "    )\n",
    "}\n",
    "\n",
    "for label_idx, class_name in classes.items():\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "    for img_filename in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_filename)\n",
    "        img_paths.append(img_path)\n",
    "        labels.append(label_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    img_paths, labels,\n",
    "    test_size=val_size,\n",
    "    random_state = seed,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.img_paths = X\n",
    "        self.labels = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.labels[index]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img, img_size=(224, 224)):\n",
    "    img = img.resize(img_size)\n",
    "    img = np.array(img)[..., :3]\n",
    "    img = torch.tensor(img).permute(2, 0, 1).float()\n",
    "    normalized_img = img / 255.0\n",
    "    \n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset object for train - test - val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WeatherDataset(\n",
    "    X_train, y_train,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = WeatherDataset(\n",
    "    X_val, y_val,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = WeatherDataset(\n",
    "    X_test, y_test,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 512\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Construction (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual Block implementation for ResNet architecture.\n",
    "\n",
    "    This block consists of two convolutional layers with Batch Normalization and ReLU activations,\n",
    "    along with an optional downsample layer to match dimensions between input and output.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv2d): First convolutional layer with kernel size 3.\n",
    "        batch_norm1 (nn.BatchNorm2d): Batch normalization after the first convolution.\n",
    "        conv2 (nn.Conv2d): Second convolutional layer with kernel size 3.\n",
    "        batch_norm2 (nn.BatchNorm2d): Batch normalization after the second convolution.\n",
    "        downsample (nn.Sequential): Optional downsampling layer to adjust input dimensions if necessary.\n",
    "        relu (nn.ReLU): ReLU activation function.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        stride (int, optional): Stride for the first convolutional layer. Default is 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # First convolutional layer: reduces dimensions based on stride and extracts features.\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Second convolutional layer: keeps dimensions consistent and refines features.\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Initialize downsample layer as an empty Sequential module.\n",
    "        self.downsample = nn.Sequential()\n",
    "\n",
    "        # Downsample the input if stride > 1 or the number of channels changes.\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),  # 1x1 convolution for channel matching.\n",
    "                nn.BatchNorm2d(out_channels)  # Normalize the downsampled features.\n",
    "            )\n",
    "\n",
    "        # ReLU activation function to introduce non-linearity.\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the Residual Block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, out_channels, new_height, new_width).\n",
    "        \"\"\"\n",
    "        # Save the input tensor as the shortcut for residual connection.\n",
    "        shortcut = x.clone()\n",
    "\n",
    "        # First convolution, normalization, and activation.\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Second convolution and normalization.\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "\n",
    "        # Add the shortcut connection (with downsampling if required).\n",
    "        x += self.downsample(shortcut)\n",
    "\n",
    "        # Apply final ReLU activation.\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, residual_block, n_blocks_lst, n_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=3)\n",
    "        self.conv2 = self.create_layer(residual_block, 64, 64, n_blocks_lst[0], 1)\n",
    "        self.conv3 = self.create_layer(residual_block, 64, 128, n_blocks_lst[1], 2)\n",
    "        self.conv4 = self.create_layer(residual_block, 128, 256, n_blocks_lst[2], 2)\n",
    "        self.conv5 = self.create_layer(residual_block, 256, 512, n_blocks_lst[3], 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, n_classes)\n",
    "    \n",
    "    def create_layer(self, residual_block, in_channels, out_channels, n_blocks, stride):\n",
    "        blocks = []\n",
    "        first_block = residual_block(in_channels, out_channels, stride)\n",
    "        blocks.append(first_block)\n",
    "        \n",
    "        for idx in range (1, n_blocks):\n",
    "            block = residual_block(out_channels, out_channels, stride)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        block_sequential = nn.Sequential(*blocks)\n",
    "        \n",
    "        return block_sequential\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(list(classes.keys()))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ResNet(\n",
    "    residual_block=ResidualBlock,\n",
    "    n_blocks_lst=[2, 2, 2, 2],\n",
    "    n_classes=n_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    loss = sum(losses) / len(losses)\n",
    "    acc = correct / total\n",
    "    \n",
    "    return loss, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIO2024-Exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
